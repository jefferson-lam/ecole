{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver configuration as a bandit problem\n",
    "\n",
    "In this tutorial we are interested in minimizing the expected branch-and-bound tree size of the SCIP solver by tuning the parameter [`branching/scorefac`](https://www.scipopt.org/doc/html/PARAMETERS.php), which takes values in the range $[0,1]$. This parameter, used in combination with the sum score function (`branching/scorefunc=s`), controls the weighting of downward and upward gain predictions in the computation of branching scores. It has a default value of 0.167.\n",
    "\n",
    "Dependencies are given for conda in the file `conda-requirements.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, optimization, and test parameters of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters set Papermill during testing, do not rename.\n",
    "train_n_items = 100\n",
    "train_n_bids = 100\n",
    "train_add_item_prob = 0.7\n",
    "optim_n_iters = 100\n",
    "optim_n_burnins = 10\n",
    "optim_seed = 42\n",
    "test_n_items = 150\n",
    "test_n_bids = 750\n",
    "test_add_item_prob = 0.7\n",
    "test_seed = 1337\n",
    "test_n_evals = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ecole as ec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Setting up the Ecole environment\n",
    "\n",
    "We formulate this parameter tuning task as a continuum-armed bandit problem, which we instantiate using a [`Configuring`](https://doc.ecole.ai/master/reference/environments.html#configuring) environment. We request no observation (non-contextual bandit), and use the negative number of nodes as a reward (tree size minimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ec.environment.Configuring(\n",
    "    # set up a few SCIP parameters\n",
    "    scip_params={\n",
    "        \"branching/scorefunc\": \"s\",  # sum score function\n",
    "        \"branching/vanillafullstrong/priority\": 666666,  # use vanillafullstrong (highest priority)\n",
    "        \"presolving/maxrounds\": 0,  # deactivate presolving\n",
    "    },\n",
    "    # pure bandit, no observation\n",
    "    observation_function=None,\n",
    "    # minimize the total number of nodes\n",
    "    reward_function=-ec.reward.NNodes(),\n",
    "    # collect additional metrics for information purposes\n",
    "    information_function={\n",
    "        \"nnodes\": ec.reward.NNodes().cumsum(),\n",
    "        \"lpiters\": ec.reward.LpIterations().cumsum(),\n",
    "        \"time\": ec.reward.SolvingTime().cumsum(),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up SCIP to use the sum score function for branching (`branching/scorefunc=s`), and the *vanillafullstrong* branching rule to mitigate the impact of branching heuristics (`branching/vanillafullstrong/priority=666666`). For the purpose of the tutorial we also deactivate presolving (`presolving/maxrounds=0`) in order to reduce computational time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up the training distribution\n",
    "\n",
    "For the purpose of this tutorial we will consider randomly generated Combinatorial Auction problems, as the problem distribution for which we want to configure the solver. We hence set up a `CombinatorialAuctionGenerator` that will generate such instances on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infinite instance generator, new instances will be generated on-the-fly\n",
    "instances = ec.instance.CombinatorialAuctionGenerator(\n",
    "    n_items=train_n_items, n_bids=train_n_bids, add_item_prob=train_add_item_prob\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we consider small-sized instances ($100\\times 100$), which are solved within seconds by SCIP but are difficult enough to produce tens of branch-and-bound nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Solving the control problem\n",
    "\n",
    "We can now readily solve the optimization problem using an off-the-shelf optimization library, such as `scikit-optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.seed(optim_seed)  # environment (SCIP)\n",
    "instances.seed(optim_seed)  # instance generator\n",
    "rng = np.random.RandomState(optim_seed)  # optimizer\n",
    "\n",
    "# set up the optimizer\n",
    "opt = skopt.Optimizer(\n",
    "    dimensions=[(0.0, 1.0)],\n",
    "    base_estimator=\"GP\",\n",
    "    n_initial_points=optim_n_burnins,\n",
    "    random_state=rng,\n",
    "    acq_func=\"PI\",\n",
    "    acq_optimizer=\"sampling\",\n",
    "    acq_optimizer_kwargs={\"n_points\": 10},\n",
    ")\n",
    "\n",
    "assert optim_n_iters > optim_n_burnins\n",
    "\n",
    "# run the optimization\n",
    "for i in range(optim_n_iters):\n",
    "\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"iteration {i+1} / {optim_n_iters}\")\n",
    "\n",
    "    # pick up a new random instance\n",
    "    instance = next(instances)\n",
    "\n",
    "    # start a new episode\n",
    "    env.reset(instance)\n",
    "\n",
    "    # get the next action from the optimizer\n",
    "    x = opt.ask()\n",
    "    action = {\"branching/scorefac\": x[0]}\n",
    "\n",
    "    # apply the action and collect the reward\n",
    "    _, _, reward, _, _ = env.step(action)\n",
    "\n",
    "    # update the optimizer\n",
    "    opt.tell(x, -reward)  # minimize the negated reward (eq. maximize the reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize the result of the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = opt.models[-1]\n",
    "\n",
    "x = np.linspace(0, 1, 500)\n",
    "x_model = opt.space.transform(x.reshape(-1, 1).tolist())\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# points sampled during optimization\n",
    "lns1 = ax1.plot(opt.Xi, opt.yi, \"r.\", markersize=8, label=\"Collected data\")\n",
    "\n",
    "# value function estimation\n",
    "y_mean, y_std = model.predict(x_model, return_std=True)\n",
    "lns2 = ax1.plot(x, y_mean, \"g--\", label=r\"Value function\")\n",
    "ax1.fill_between(\n",
    "    x, y_mean - 1.6 * y_std, y_mean + 1.6 * y_std, alpha=0.2, fc=\"g\", ec=\"None\"\n",
    ")\n",
    "\n",
    "# probability of improvement estimation\n",
    "x_pi = skopt.acquisition.gaussian_pi(x_model, model, y_opt=np.min(opt.yi))\n",
    "ax2 = ax1.twinx()\n",
    "lns3 = ax2.plot(x, x_pi, \"b\", label=\"Prob. of improvement\")\n",
    "\n",
    "ax1.set_title(f\"Model obtained after {optim_n_iters} iterations\")\n",
    "ax1.set_ylabel(f\"number of nodes (neg. reward)\")\n",
    "ax1.set_xlabel(f\"$branching/scorefac$ parameter value (action)\")\n",
    "\n",
    "ax2.set_ylabel(f\"Probability value\")\n",
    "\n",
    "# Legend\n",
    "lns = lns1 + lns2 + lns3\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax1.legend(lns, labs, loc=\"upper center\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# get best value based on a grid search on the value function estimator\n",
    "best_value = x[np.argmin(y_mean)]\n",
    "print(f\"Best parameter value: branching/scorefac = {best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation on harder instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set up more challenging instances\n",
    "test_instances = ec.instance.CombinatorialAuctionGenerator(\n",
    "    n_items=test_n_items, n_bids=test_n_bids, add_item_prob=test_add_item_prob\n",
    ")\n",
    "\n",
    "for policy in (\"default\", \"learned\"):\n",
    "\n",
    "    print(f\"evaluating policy '{policy}'\")\n",
    "    results = []\n",
    "\n",
    "    for i in range(test_n_evals):\n",
    "\n",
    "        # evaluate each policy in the exact same settings\n",
    "        env.seed(test_seed + i)  # environment (SCIP)\n",
    "        test_instances.seed(test_seed + i)  # instance generator\n",
    "\n",
    "        # pick up the next instance\n",
    "        instance = next(test_instances)\n",
    "\n",
    "        # set up the episode initial state\n",
    "        env.reset(instance)\n",
    "\n",
    "        # get the action from the policy\n",
    "        if policy == \"default\":\n",
    "            action = {}  # will use the default value from SCIP\n",
    "        else:\n",
    "            action = {\"branching/scorefac\": best_value}\n",
    "\n",
    "        # apply the action and collect the reward\n",
    "        _, _, _, _, info = env.step(action)\n",
    "\n",
    "        print(\n",
    "            f\"  instance {i+1}: {info['nnodes']} nodes, {info['lpiters']} lpiters, {info['time']} secs\"\n",
    "        )\n",
    "\n",
    "        results.append(info[\"nnodes\"])\n",
    "\n",
    "    print(f\"  average performance: {np.mean(results)} nodes\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
